import gzip, json, os, requests, csv, sys, time
from pathlib import Path
from jsonschema import validate

# [ì„¤ì •] ì¸í”„ë¼ ë° ê²½ë¡œ
INDEX_URL = "https://www.gutenberg.org/cache/epub/feeds/pg_catalog.csv"
STATE_PATH = Path("state.json")
OUT_DIR = Path("products")
OUT_DIR.mkdir(exist_ok=True)
MAX_BOOKS = 5  # AI ë¶„ì„ í’ˆì§ˆ ë° ì†ë„ ì¡°ì ˆì„ ìœ„í•´ ì´ˆê¸°ê°’ì€ ì‘ê²Œ ì„¤ì •

# [ë³´ì•ˆ] GitHub Secretsì—ì„œ API í‚¤ ë¡œë“œ
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# [HG2] Schema ë¡œë“œ
try:
    SCHEMA = json.loads(Path("schema.json").read_text(encoding="utf-8"))
except:
    print("âš ï¸ Schema missing, using fallback")
    SCHEMA = {"type": "object", "required": ["book_id"]}

def load_processed_ids():
    """ìƒíƒœ ë°ì´í„° ë¡œë“œ: ì¤‘ë³µ ìƒì‚° ë°©ì§€"""
    if not STATE_PATH.exists(): 
        return set()
    try: 
        return set(str(bid) for bid in json.loads(STATE_PATH.read_text(encoding="utf-8")).get("processed_ids", []))
    except: 
        return set()

def fetch_work_queue():
    """7ë§Œ ê¶Œ ëª©ë¡ ì¤‘ ê³ ê°€ì¹˜ ìì‚° ì¶”ì¶œ"""
    processed = load_processed_ids()
    
    try:
        resp = requests.get(INDEX_URL, timeout=30)
        resp.raise_for_status()
    except requests.RequestException as e:
        print(f"âŒ [Network Fatality] Failed to fetch index: {e}")
        return []
    
    resp.encoding = 'utf-8'
    reader = csv.DictReader(resp.text.splitlines())
    
    # ì»¬ëŸ¼ëª… ì •ê·œí™”
    fieldnames = {k.strip(): k for k in (reader.fieldnames or [])}
    text_key = fieldnames.get('Text#')
    title_key = fieldnames.get('Title')
    
    # Downloads ì»¬ëŸ¼ íƒìƒ‰
    possible_keys = ['Downloads', 'Download Count', 'downloads']
    actual_key = next((fieldnames.get(k) for k in possible_keys if fieldnames.get(k)), None)
    
    all_books = list(reader)
    if actual_key:
        all_books.sort(key=lambda x: int(x.get(actual_key, 0) or 0), reverse=True)
    
    queue = []
    for row in all_books:
        book_id = row.get(text_key, '').strip() if text_key else ''
        if book_id and book_id not in processed:
            queue.append({
                "id": book_id, 
                "title": row.get(title_key, 'Unknown Title').strip()
            })
        if len(queue) >= MAX_BOOKS: 
            break
    return queue

def get_ai_insight(title):
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì „ëµì  í†µì°° ìƒì„±"""
    if not GEMINI_API_KEY:
        return "Insight pending: API Key missing."
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    prompt = {
        "contents": [{
            "parts": [{
                "text": f"Analyze the classic book '{title}' and provide one 'Irreversible Insight' for global financial architecture optimization. Keep it under 200 characters."
            }]
        }]
    }
    
    try:
        response = requests.post(url, headers=headers, json=prompt, timeout=10)
        response.raise_for_status()
        return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
    except Exception as e:
        print(f"âš ï¸ AI Error for {title}: {e}")
        return f"Strategic analysis of {title} in progress."

def generate_asset(book_id, title):
    """[ìƒì‚° ë¡œì§] AI ê¸°ë°˜ ì§€ì‹ ìì‚° ìƒì„±"""
    # AI ì§€ëŠ¥ ì£¼ì…
    insight = get_ai_insight(title)
    
    # Rate Limit ë°©ì§€ë¥¼ ìœ„í•œ 4ì´ˆ ëŒ€ê¸° (Gemini ë¬´ë£Œ í‹°ì–´: 15 RPM)
    time.sleep(4) 
    
    safe_title = str(title or "Unknown")[:50]
    return {
        "book_id": str(book_id),
        "audience": "professional",
        "irreversible_insight": insight,
        "cards": [
            "Structural Audit: Identify patterns",
            "Strategic Pivot: Reallocate resources", 
            "Scalable Growth: Standardize architecture"
        ],
        "quiz": [
            {"q": f"Core insight of {safe_title}?", "a": "AI-generated optimization"},
            {"q": "Risk Control?", "a": "Cost guard verification"},
            {"q": "Next Step?", "a": "Execute"}
        ],
        "script_60s": f"AI-powered insight on {safe_title}.",
        "keywords": ["AI-Insight", "Strategy", "Optimization"]
    }

def generate_sitemap(processed_ids):
    """ëª¨ë“  ìì‚°ì„ êµ¬ê¸€ì— ì‹ ê³ í•˜ê¸° ìœ„í•œ sitemap.xml ìƒì„±"""
    base_url = "https://pauljangtv-create.github.io/gutenberg-galaxy/"
    sitemap = ['<?xml version="1.0" encoding="UTF-8"?>', '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">']
    
    sitemap.append(f"<url><loc>{base_url}</loc><priority>1.0</priority></url>")
    
    for bid in list(processed_ids)[-5000:]:
        sitemap.append(f"<url><loc>{base_url}?id={bid}</loc><priority>0.8</priority></url>")
    
    sitemap.append('</urlset>')
    Path("sitemap.xml").write_text("\n".join(sitemap), encoding="utf-8")
    Path("robots.txt").write_text(f"User-agent: *\nAllow: /\nSitemap: {base_url}sitemap.xml", encoding="utf-8")
    print("âœ… Sitemap generated for SEO")

def main():
    """
    [Antifragile Control System]
    HG3: Cost Guard with AI API validation
    """
    
    # --- [HG3] COST GUARD START (DO NOT REMOVE) ---
    PAID_LLM_ENABLED = bool(GEMINI_API_KEY)  # auditorê°€ ê²€ì¦í•˜ëŠ” ë³€ìˆ˜
    MAX_TOTAL_COST = 10.0  # ì„¤ì •ëœ ì¼ì¼ ì˜ˆì‚° ($)
    current_estimated_cost = 0.0  # Gemini FlashëŠ” ë¬´ë£Œì´ë¯€ë¡œ 0
    
    # API í‚¤ ê²€ì¦
    if not GEMINI_API_KEY:
        print("ğŸ›‘ [FATALITY] GEMINI_API_KEY missing. System freeze.")
        print("ğŸ’¡ Set GitHub Secret: GEMINI_API_KEY")
        sys.exit(1)
    
    # ë¦¬ìŠ¤í¬ ê°ì§€ ì‹œ ì¦‰ì‹œ ì‹œìŠ¤í…œ ì¤‘ë‹¨
    if PAID_LLM_ENABLED and current_estimated_cost > MAX_TOTAL_COST:
        print("ğŸ›‘ [FATALITY] Cost threshold exceeded.")
        sys.exit(1)
    # --- [HG3] COST GUARD END ---

    print(f"ğŸ›¡ï¸ [HG3 PASS] Risk/Cost safety verified: ${current_estimated_cost}")
    print(f"ğŸ¤– AI Mode: {'Enabled' if PAID_LLM_ENABLED else 'Disabled'}")

    # 1. ìƒì‚° ì¤€ë¹„ ë° ìƒíƒœ ë¡œë“œ
    queue = fetch_work_queue()
    processed_ids = list(load_processed_ids())
    
    if not queue:
        print("âš ï¸ No pending tasks. System idling.")
        return

    print(f"ğŸ“‹ Queue size: {len(queue)} books")

    # 2. AI ê¸°ë°˜ ìƒì‚° ë£¨í”„
    for item in queue:
        try:
            print(f"ğŸ”„ Processing: {item['id']} - {item['title'][:30]}...")
            
            # AIë¡œ ê°œë³„ ìì‚° ìƒì„± ë° ê²€ìˆ˜
            data = generate_asset(item['id'], item['title'])
            validate(instance=data, schema=SCHEMA)
            
            # HG4: ì••ì¶• ì €ì¥ ë° ìì‚°í™”
            file_path = OUT_DIR / f"{item['id']}.json.gz"
            with gzip.open(file_path, "wb") as f:
                f.write(json.dumps(data, ensure_ascii=False).encode("utf-8"))
            
            processed_ids.append(item['id'])
            print(f"âœ… Produced: {item['id']}")
            
        except Exception as e:
            print(f"âŒ Skip ID {item['id']}: {e}")
            continue

    # 3. ìƒíƒœ ê¸°ë¡ ë° ë™ê¸°í™”
    final_state = {"processed_ids": sorted(list(set(processed_ids)))}
    STATE_PATH.write_text(json.dumps(final_state, indent=2), encoding="utf-8")
    
    # 4. SEO: Sitemap ìƒì„±
    generate_sitemap(processed_ids)
    
    print(f"ğŸ‰ Production complete: {len(queue)} assets generated")

if __name__ == "__main__":
    main()
