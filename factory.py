import gzip, json, os, requests, csv, sys, time
from pathlib import Path
from jsonschema import validate

# [ì„¤ì •] ì¸í”„ë¼ ë° ê²½ë¡œ
INDEX_URL = "https://www.gutenberg.org/cache/epub/feeds/pg_catalog.csv"
STATE_PATH = Path("state.json")
OUT_DIR = Path("products")
OUT_DIR.mkdir(exist_ok=True)
MAX_BOOKS = 5  # AI ë¶„ì„ í’ˆì§ˆ ë° ì†ë„ ì¡°ì ˆì„ ìœ„í•´ ì´ˆê¸°ê°’ì€ ì‘ê²Œ ì„¤ì •

# [ë³´ì•ˆ] GitHub Secretsì—ì„œ API í‚¤ ë¡œë“œ
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# [HG2] Schema ë¡œë“œ
try:
    SCHEMA = json.loads(Path("schema.json").read_text(encoding="utf-8"))
except:
    print("âš ï¸ Schema missing, using fallback")
    SCHEMA = {"type": "object", "required": ["book_id"]}

def load_processed_ids():
    """ìƒíƒœ ë°ì´í„° ë¡œë“œ: ì¤‘ë³µ ìƒì‚° ë°©ì§€"""
    if not STATE_PATH.exists(): 
        return set()
    try: 
        return set(str(bid) for bid in json.loads(STATE_PATH.read_text(encoding="utf-8")).get("processed_ids", []))
    except: 
        return set()

def fetch_work_queue():
    """7ë§Œ ê¶Œ ëª©ë¡ ì¤‘ ê³ ê°€ì¹˜ ìì‚° ì¶”ì¶œ (ì œëª©+ì €ì ë©”íƒ€ë°ì´í„° í¬í•¨)"""
    processed = load_processed_ids()
    
    try:
        resp = requests.get(INDEX_URL, timeout=30)
        resp.raise_for_status()
    except requests.RequestException as e:
        print(f"âŒ [Network Fatality] Failed to fetch index: {e}")
        return []
    
    resp.encoding = 'utf-8'
    reader = csv.DictReader(resp.text.splitlines())
    
    # ì»¬ëŸ¼ëª… ì •ê·œí™”
    fieldnames = {k.strip(): k for k in (reader.fieldnames or [])}
    text_key = fieldnames.get('Text#')
    title_key = fieldnames.get('Title')
    author_key = fieldnames.get('Authors')  # [ì¶”ê°€] ì €ì ì •ë³´
    subjects_key = fieldnames.get('Subjects')  # [ì¶”ê°€] ì¥ë¥´/ì£¼ì œ ì •ë³´
    
    # Downloads ì»¬ëŸ¼ íƒìƒ‰
    possible_keys = ['Downloads', 'Download Count', 'downloads']
    actual_key = next((fieldnames.get(k) for k in possible_keys if fieldnames.get(k)), None)
    
    all_books = list(reader)
    if actual_key:
        all_books.sort(key=lambda x: int(x.get(actual_key, 0) or 0), reverse=True)
    
    queue = []
    for row in all_books:
        book_id = row.get(text_key, '').strip() if text_key else ''
        if book_id and book_id not in processed:
            queue.append({
                "id": book_id, 
                "title": row.get(title_key, 'Unknown Title').strip(),
                "author": row.get(author_key, 'Unknown Author').strip() if author_key else 'Unknown Author',
                "subjects": row.get(subjects_key, '').strip() if subjects_key else ''
            })
        if len(queue) >= MAX_BOOKS: 
            break
    return queue

def get_ai_insight(title, author, subjects):
    """
    [Step 1] AI í”„ë¡¬í”„íŠ¸ ê³ ë„í™”: ë„ì„œë³„ ë§¥ë½ì„ ê°•ì œ ë°˜ì˜
    """
    if not GEMINI_API_KEY:
        return f"Insight for '{title}' by {author} pending: API Key missing."
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    # [í•µì‹¬ ê°œì„ ] ê³ ìœ  ë§¥ë½ ê°•ì œ ì£¼ì…
    context = f"Author: {author}" if author != 'Unknown Author' else ""
    if subjects:
        context += f" | Genre/Subjects: {subjects[:100]}"
    
    prompt = {
        "contents": [{
            "parts": [{
                "text": (
                    f"Book Title: '{title}'\n"
                    f"{context}\n\n"
                    f"Task: Extract ONE UNIQUE strategic business insight from THIS SPECIFIC BOOK "
                    f"for global financial architecture optimization. "
                    f"Do NOT use generic advice like 'optimize resources' or 'be strategic'. "
                    f"Reflect the book's SPECIFIC themes, plot, or philosophical arguments. "
                    f"Must be actionable and distinctive to THIS book. "
                    f"Keep it under 200 characters in English."
                )
            }]
        }]
    }
    
    try:
        response = requests.post(url, headers=headers, json=prompt, timeout=15)
        response.raise_for_status()
        insight = response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
        
        # [Validation] ë„ˆë¬´ ì¼ë°˜ì ì¸ ì‘ë‹µ í•„í„°ë§
        generic_keywords = ['optimize', 'strategic', 'resources', 'efficiency', 'important']
        if all(keyword not in insight.lower() for keyword in generic_keywords[:2]):
            return insight
        else:
            # ì¬ì‹œë„ ë˜ëŠ” í´ë°±
            return f"Analysis of '{title}': {insight}"
            
    except Exception as e:
        print(f"âš ï¸ AI Error for '{title}': {e}")
        return f"Strategic analysis of '{title}' by {author} in progress."

def generate_asset(book_id, title, author, subjects):
    """
    [Step 2] ë°ì´í„° êµ¬ì¡° ë‚´ ì¶œì²˜ ëª…ì‹œ ë° AI í†µì°° ì£¼ì…
    """
    # AI ì§€ëŠ¥ ì£¼ì… (ê³ ë„í™”ëœ í”„ë¡¬í”„íŠ¸)
    insight = get_ai_insight(title, author, subjects)
    
    # Rate Limit ë°©ì§€ë¥¼ ìœ„í•œ 4ì´ˆ ëŒ€ê¸° (Gemini ë¬´ë£Œ í‹°ì–´: 15 RPM)
    time.sleep(4) 
    
    safe_title = str(title or "Unknown")[:80]
    safe_author = str(author or "Unknown")[:50]
    
    return {
        "book_id": str(book_id),
        "source_book": safe_title,  # [ì¶”ê°€] ì¶œì²˜ ë„ì„œëª… ëª…ì‹œ
        "source_author": safe_author,  # [ì¶”ê°€] ì €ì ëª…ì‹œ
        "audience": "professional",
        "irreversible_insight": insight,
        "cards": [
            f"Structural Audit: Analyze '{safe_title[:30]}' patterns",
            f"Strategic Pivot: Apply {safe_author}'s framework", 
            "Scalable Growth: Standardize architecture"
        ],
        "quiz": [
            {"q": f"Core insight of '{safe_title[:30]}'?", "a": "Book-specific optimization"},
            {"q": f"Who wrote this?", "a": safe_author},
            {"q": "Application?", "a": "Financial architecture"}
        ],
        "script_60s": f"AI-powered insight from '{safe_title}' by {safe_author}.",
        "keywords": ["AI-Insight", safe_author.split()[0] if safe_author else "Strategy", "Book-Analysis"]
    }

def generate_sitemap(processed_ids):
    """ëª¨ë“  ìì‚°ì„ êµ¬ê¸€ì— ì‹ ê³ í•˜ê¸° ìœ„í•œ sitemap.xml ìƒì„±"""
    base_url = "https://pauljangtv-create.github.io/gutenberg-galaxy/"
    sitemap = ['<?xml version="1.0" encoding="UTF-8"?>', '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">']
    
    sitemap.append(f"<url><loc>{base_url}</loc><priority>1.0</priority></url>")
    
    for bid in list(processed_ids)[-5000:]:
        sitemap.append(f"<url><loc>{base_url}?id={bid}</loc><priority>0.8</priority></url>")
    
    sitemap.append('</urlset>')
    Path("sitemap.xml").write_text("\n".join(sitemap), encoding="utf-8")
    Path("robots.txt").write_text(f"User-agent: *\nAllow: /\nSitemap: {base_url}sitemap.xml", encoding="utf-8")
    print("âœ… Sitemap generated for SEO")

def main():
    """
    [Antifragile Control System]
    HG3: Cost Guard with AI API validation
    """
    
    # --- [HG3] COST GUARD START (DO NOT REMOVE) ---
    PAID_LLM_ENABLED = bool(GEMINI_API_KEY)  # auditorê°€ ê²€ì¦í•˜ëŠ” ë³€ìˆ˜
    MAX_TOTAL_COST = 10.0  # ì„¤ì •ëœ ì¼ì¼ ì˜ˆì‚° ($)
    current_estimated_cost = 0.0  # Gemini FlashëŠ” ë¬´ë£Œì´ë¯€ë¡œ 0
    
    # API í‚¤ ê²€ì¦
    if not GEMINI_API_KEY:
        print("ğŸ›‘ [FATALITY] GEMINI_API_KEY missing. System freeze.")
        print("ğŸ’¡ Set GitHub Secret: GEMINI_API_KEY")
        sys.exit(1)
    
    # ë¦¬ìŠ¤í¬ ê°ì§€ ì‹œ ì¦‰ì‹œ ì‹œìŠ¤í…œ ì¤‘ë‹¨
    if PAID_LLM_ENABLED and current_estimated_cost > MAX_TOTAL_COST:
        print("ğŸ›‘ [FATALITY] Cost threshold exceeded.")
        sys.exit(1)
    # --- [HG3] COST GUARD END ---

    print(f"ğŸ›¡ï¸ [HG3 PASS] Risk/Cost safety verified: ${current_estimated_cost}")
    print(f"ğŸ¤– AI Mode: {'Enabled (Personalized)' if PAID_LLM_ENABLED else 'Disabled'}")

    # 1. ìƒì‚° ì¤€ë¹„ ë° ìƒíƒœ ë¡œë“œ
    queue = fetch_work_queue()
    processed_ids = list(load_processed_ids())
    
    if not queue:
        print("âš ï¸ No pending tasks. System idling.")
        return

    print(f"ğŸ“‹ Queue size: {len(queue)} books")

    # 2. AI ê¸°ë°˜ ë§ì¶¤í˜• ìƒì‚° ë£¨í”„
    for item in queue:
        try:
            print(f"ğŸ”„ Processing: {item['id']} - '{item['title'][:40]}' by {item['author'][:30]}")
            
            # AIë¡œ ê°œë³„ ìì‚° ìƒì„± (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
            data = generate_asset(
                item['id'], 
                item['title'], 
                item['author'],
                item['subjects']
            )
            validate(instance=data, schema=SCHEMA)
            
            # HG4: ì••ì¶• ì €ì¥ ë° ìì‚°í™”
            file_path = OUT_DIR / f"{item['id']}.json.gz"
            with gzip.open(file_path, "wb") as f:
                f.write(json.dumps(data, ensure_ascii=False).encode("utf-8"))
            
            processed_ids.append(item['id'])
            print(f"âœ… Produced: {item['id']} | Insight: {data['irreversible_insight'][:60]}...")
            
        except Exception as e:
            print(f"âŒ Skip ID {item['id']}: {e}")
            continue

    # 3. ìƒíƒœ ê¸°ë¡ ë° ë™ê¸°í™”
    final_state = {"processed_ids": sorted(list(set(processed_ids)))}
    STATE_PATH.write_text(json.dumps(final_state, indent=2), encoding="utf-8")
    
    # 4. SEO: Sitemap ìƒì„±
    generate_sitemap(processed_ids)
    
    print(f"ğŸ‰ Production complete: {len(queue)} personalized assets generated")

if __name__ == "__main__":
    main()
